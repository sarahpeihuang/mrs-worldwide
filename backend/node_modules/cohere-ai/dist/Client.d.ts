/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "./environments";
import * as core from "./core";
import * as Cohere from "./api";
import { Connectors } from "./api/resources/connectors/client/Client";
export declare namespace CohereClient {
    interface Options {
        environment?: core.Supplier<environments.CohereEnvironment | string>;
        token: core.Supplier<core.BearerToken>;
    }
    interface RequestOptions {
        timeoutInSeconds?: number;
        maxRetries?: number;
    }
}
export declare class CohereClient {
    protected readonly _options: CohereClient.Options;
    constructor(_options: CohereClient.Options);
    /**
     * The `chat` endpoint allows users to have conversations with a Large Language Model (LLM) from Cohere. Users can send messages as part of a persisted conversation using the `conversation_id` parameter, or they can pass in their own conversation history using the `chat_history` parameter.
     * The endpoint features additional parameters such as [connectors](https://docs.cohere.com/docs/connectors) and `documents` that enable conversations enriched by external knowledge. We call this "Retrieval Augmented Generation", or "RAG".
     *
     */
    chatStream(request: Cohere.ChatStreamRequest, requestOptions?: CohereClient.RequestOptions): Promise<core.Stream<Cohere.StreamedChatResponse>>;
    /**
     * The `chat` endpoint allows users to have conversations with a Large Language Model (LLM) from Cohere. Users can send messages as part of a persisted conversation using the `conversation_id` parameter, or they can pass in their own conversation history using the `chat_history` parameter.
     * The endpoint features additional parameters such as [connectors](https://docs.cohere.com/docs/connectors) and `documents` that enable conversations enriched by external knowledge. We call this "Retrieval Augmented Generation", or "RAG".
     *
     */
    chat(request: Cohere.ChatRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.NonStreamedChatResponse>;
    /**
     * This endpoint generates realistic text conditioned on a given input.
     * @throws {@link Cohere.BadRequestError}
     * @throws {@link Cohere.InternalServerError}
     */
    generate(request: Cohere.GenerateRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.Generation>;
    /**
     * This endpoint returns text embeddings. An embedding is a list of floating point numbers that captures semantic information about the text that it represents.
     *
     * Embeddings can be used to create text classifiers as well as empower semantic search. To learn more about embeddings, see the embedding page.
     *
     * If you want to learn more how to use the embedding model, have a look at the [Semantic Search Guide](/docs/semantic-search).
     * @throws {@link Cohere.BadRequestError}
     * @throws {@link Cohere.InternalServerError}
     */
    embed(request: Cohere.EmbedRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.EmbedResponse>;
    /**
     * This endpoint takes in a query and a list of texts and produces an ordered array with each text assigned a relevance score.
     */
    rerank(request: Cohere.RerankRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.RerankResponse>;
    /**
     * This endpoint makes a prediction about which label fits the specified text inputs best. To make a prediction, Classify uses the provided `examples` of text + label pairs as a reference.
     * Note: [Custom Models](/training-representation-models) trained on classification examples don't require the `examples` parameter to be passed in explicitly.
     * @throws {@link Cohere.BadRequestError}
     * @throws {@link Cohere.InternalServerError}
     */
    classify(request: Cohere.ClassifyRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.ClassifyResponse>;
    /**
     * This endpoint identifies which language each of the provided texts is written in.
     *
     * @example
     *     await cohere.detectLanguage({
     *         texts: []
     *     })
     */
    detectLanguage(request: Cohere.DetectLanguageRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.DetectLanguageResponse>;
    /**
     * This endpoint generates a summary in English for a given text.
     */
    summarize(request: Cohere.SummarizeRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.SummarizeResponse>;
    /**
     * This endpoint splits input text into smaller units called tokens using byte-pair encoding (BPE). To learn more about tokenization and byte pair encoding, see the tokens page.
     * @throws {@link Cohere.BadRequestError}
     * @throws {@link Cohere.InternalServerError}
     */
    tokenize(request: Cohere.TokenizeRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.TokenizeResponse>;
    /**
     * This endpoint takes tokens using byte-pair encoding and returns their text representation. To learn more about tokenization and byte pair encoding, see the tokens page.
     */
    detokenize(request: Cohere.DetokenizeRequest, requestOptions?: CohereClient.RequestOptions): Promise<Cohere.DetokenizeResponse>;
    protected _connectors: Connectors | undefined;
    get connectors(): Connectors;
    protected _getAuthorizationHeader(): Promise<string>;
}
